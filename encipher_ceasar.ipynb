{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# batch.py"
      ],
      "metadata": {
        "id": "NJczfGSHEtUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "\n",
        "num_examples = 128\n",
        "message_length = 32\n",
        "\n",
        " \n",
        "def dataset(num_examples):\n",
        "   \n",
        "    dataset = []\n",
        "    for x in range(num_examples):\n",
        "        ex_out = ''.join([random.choice(vocab) for x in range(message_length)])\n",
        "        ex_in = encrypt(''.join(ex_out))\n",
        "        ex_in = [vocab.index(x) for x in ex_in]\n",
        "        ex_out = [vocab.index(x) for x in ex_out]\n",
        "        dataset.append([torch.tensor(ex_in), torch.tensor(ex_out)])\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "n-OD5zk5QVU_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#cipher.py"
      ],
      "metadata": {
        "id": "EDQYT-_KPJCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "key = 3\n",
        "vocab = [char for char in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ-']\n",
        "\n",
        "\n",
        "def encrypt(text):\n",
        "   \n",
        "    indexes = [vocab.index(char) for char in text]\n",
        "    encrypted_indexes = [(idx + key) % len(vocab) for idx in indexes]\n",
        "    encrypted_chars = [vocab[idx] for idx in encrypted_indexes]\n",
        "    encrypted = ''.join(encrypted_chars)\n",
        "    return encrypted\n",
        "\n",
        "print(encrypt('ABCDEFGHIJKLMNOPQRSTUVWXYZ-'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXO-DDwqRc5s",
        "outputId": "4f5c637a-e85d-4228-ef47-515a82fbc274"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEFGHIJKLMNOPQRSTUVWXYZ-ABC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model.py"
      ],
      "metadata": {
        "id": "RFOdB54TRlZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 10\n",
        "hidden_dim = 10\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "embed = torch.nn.Embedding(vocab_size, embedding_dim)\n",
        "lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
        "linear = torch.nn.Linear(hidden_dim, vocab_size)\n",
        "softmax = torch.nn.functional.softmax\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(list(embed.parameters()) + list(lstm.parameters())\n",
        "                             + list(linear.parameters()), lr=0.001)"
      ],
      "metadata": {
        "id": "RO-VuOaERtHh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train.py"
      ],
      "metadata": {
        "id": "F4qWa9lLRyGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "accuracies, max_accuracy = [], 0\n",
        "for x in range(num_epochs):\n",
        "    print('Epoch: {}'.format(x))\n",
        "    for encrypted, original in dataset(num_examples):\n",
        "        lstm_in = embed(encrypted)\n",
        "        lstm_in = lstm_in.unsqueeze(1)\n",
        "        lstm_out, lstm_hidden = lstm(lstm_in, zero_hidden())\n",
        "        scores = linear(lstm_out)        \n",
        "        scores = scores.transpose(1, 2)        \n",
        "        original = original.unsqueeze(1)        \n",
        "        loss = loss_fn(scores, original) \n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "    print('Loss: {:6.4f}'.format(loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecGCTncpR2o1",
        "outputId": "e535c019-2b9b-496e-a0ec-41e25369e081"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Loss: 2.7491\n",
            "Epoch: 1\n",
            "Loss: 1.7264\n",
            "Epoch: 2\n",
            "Loss: 0.8279\n",
            "Epoch: 3\n",
            "Loss: 0.4849\n",
            "Epoch: 4\n",
            "Loss: 0.2186\n",
            "Epoch: 5\n",
            "Loss: 0.1132\n",
            "Epoch: 6\n",
            "Loss: 0.0765\n",
            "Epoch: 7\n",
            "Loss: 0.0453\n",
            "Epoch: 8\n",
            "Loss: 0.0237\n",
            "Epoch: 9\n",
            "Loss: 0.0161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# valid.py"
      ],
      "metadata": {
        "id": "QPY_M2SYR9-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    with torch.no_grad():\n",
        "        matches, total = 0, 0\n",
        "        for encrypted, original in dataset(num_examples):\n",
        "            lstm_in = embed(encrypted)\n",
        "            lstm_in = lstm_in.unsqueeze(1)\n",
        "            lstm_out, lstm_hidden = lstm(lstm_in, zero_hidden())\n",
        "            scores = linear(lstm_out)            \n",
        "            predictions = softmax(scores, dim=2)            \n",
        "            _, batch_out = predictions.max(dim=2)            \n",
        "            batch_out = batch_out.squeeze(1)\n",
        "            # Calculate accuracy\n",
        "            matches += torch.eq(batch_out, original).sum().item()\n",
        "            total += torch.numel(batch_out)\n",
        "        accuracy = matches / total\n",
        "        print('Accuracy: {:4.2f}%'.format(accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B51gaFlgSFVl",
        "outputId": "dec7df6c-a3c0-4d35-8021-c0241734e081"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00%\n"
          ]
        }
      ]
    }
  ]
}